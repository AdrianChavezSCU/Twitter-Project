{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "import tweepy\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "#These are display options in order to help the dataframe outputs not be truncated\n",
    "pd.options.display.max_columns = 50 \n",
    "pd.options.display.max_rows = 50 \n",
    "pd.options.display.width = 120 \n",
    "pd.options.display.max_colwidth = 110\n",
    "\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API \n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET =''\n",
    "OAUTH_TOKEN = ''\n",
    "OAUTH_TOKEN_SECRET = ''\n",
    "    \n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is just to test if the connection was established. Should only have 15 items in this. \n",
    "results = api.search(q=\"%23blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@matarosario831 - Rosario Mata (2015-10-07 18:36:11)\n",
      "RT @GDoblesMusic: ¬øUn poco de #blues para terminar la semana? Inspirado en el piano les regalo esta linda melod√≠a #BuenViernes https://t.co‚Ä¶\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Simple function to print individual tweets\n",
    "def print_tweet(tweet): \n",
    "    print \"@%s - %s (%s)\" % (tweet.user.screen_name, tweet.user.name, tweet.user.created_at)\n",
    "    print tweet.text\n",
    "    \n",
    "tweet = results[0]\n",
    "print (print_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "#This is what gets all the tweets. I believe that 5000 is currently the max items you can get from using the REST API for twitter\n",
    "for tweet in tweepy.Cursor(api.search, q = '%23blues').items(5000):\n",
    "    results.append(tweet)\n",
    "    \n",
    "print len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870\n"
     ]
    }
   ],
   "source": [
    "#This function puts your results into a dataframe that makes it much easier to read and work with. \n",
    "#Each column in the dataframe corresponds to the [''] part of it\n",
    "def process_results(results):\n",
    "    \n",
    "    id_list = [tweet.id for tweet in results]\n",
    "    \n",
    "    df = pd.DataFrame(id_list, columns=[\"id\"])\n",
    "    \n",
    "    #Processing Tweet data \n",
    "    df['text'] = [tweet.text for tweet in results]\n",
    "    df['created_at'] = [tweet.created_at for tweet in results]\n",
    "    df['retweet_count'] = [tweet.retweet_count for tweet in results]\n",
    "    df['favorite_count'] = [tweet.favorite_count for tweet in results]\n",
    "    \n",
    "    #Processing User Data\n",
    "    df['user_screen_name'] = [tweet.author.screen_name for tweet in results]\n",
    "    df['user_name'] = [tweet.author.name for tweet in results]\n",
    "    df['user_location'] = [tweet.author.location for tweet in results]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = process_results(results)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>774432361832325120</td>\n",
       "      <td>RT @GDoblesMusic: ¬øUn poco de #blues para term...</td>\n",
       "      <td>2016-09-10 02:20:37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>matarosario831</td>\n",
       "      <td>Rosario Mata</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>774432213802835968</td>\n",
       "      <td>#IWokeUp @McNeillShona https://t.co/Ofh71bdZOE...</td>\n",
       "      <td>2016-09-10 02:20:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lov3rzLov3You</td>\n",
       "      <td>Michelle #LOV3RZ</td>\n",
       "      <td>Worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>774431974354288640</td>\n",
       "      <td>#galveston #texas #blues #fuckinword @ Old Qua...</td>\n",
       "      <td>2016-09-10 02:19:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>manny9000</td>\n",
       "      <td>manny salazar</td>\n",
       "      <td>Houston Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>774431387017474048</td>\n",
       "      <td>#BBKing #BluesLegend Live at the Regal by B.B....</td>\n",
       "      <td>2016-09-10 02:16:45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HotTrends8</td>\n",
       "      <td>Google Hot Trends</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>774430888197259264</td>\n",
       "      <td>Listening to Looking Good by Magic Sam on http...</td>\n",
       "      <td>2016-09-10 02:14:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Latitude23R</td>\n",
       "      <td>Latitude23 Radio</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>774430346498768896</td>\n",
       "      <td>RT @HunterAHomistek: Stevie Ray Vaughan's best...</td>\n",
       "      <td>2016-09-10 02:12:37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>homistek</td>\n",
       "      <td>Mr marty</td>\n",
       "      <td>Planet earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>774430248574324736</td>\n",
       "      <td>#doublebass #bass #bassguitar #jamsession #beb...</td>\n",
       "      <td>2016-09-10 02:12:14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shulman_susan</td>\n",
       "      <td>susan shulman</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>774429935138209792</td>\n",
       "      <td>@Marlin Saner Rain For Africa https://t.co/3fk...</td>\n",
       "      <td>2016-09-10 02:10:59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lorraine_jazz</td>\n",
       "      <td>Lorraine Jazz</td>\n",
       "      <td>Nancy, Lorraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>774429930969042944</td>\n",
       "      <td>Now Playing, Little Freddie King ‚Äî Louisiana T...</td>\n",
       "      <td>2016-09-10 02:10:58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wnmcradio</td>\n",
       "      <td>WNMC Radio Playlist</td>\n",
       "      <td>Traverse City, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>774429767223369728</td>\n",
       "      <td>Listen to my #awardwinningsong #moonblues on #...</td>\n",
       "      <td>2016-09-10 02:10:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>delaine2511</td>\n",
       "      <td>Vanessa Delaine</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>774428983261671424</td>\n",
       "      <td>#StLouis Rare NHL St. Louis #Blues Sean Glanvi...</td>\n",
       "      <td>2016-09-10 02:07:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FaithCrossman</td>\n",
       "      <td>Faith Crossman</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>774428657477644288</td>\n",
       "      <td>@RVG Bad Habit https://t.co/3fkWSJWzFp #japan ...</td>\n",
       "      <td>2016-09-10 02:05:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lorraine_jazz</td>\n",
       "      <td>Lorraine Jazz</td>\n",
       "      <td>Nancy, Lorraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>774427946585100289</td>\n",
       "      <td>RT @MECStateChamber: The MS #Blues Trail, now ...</td>\n",
       "      <td>2016-09-10 02:03:05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>JNewell53</td>\n",
       "      <td>Two Feathers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>774427136694235136</td>\n",
       "      <td>#BBKing #BluesLegend B.B.KING - THERE MUST BE ...</td>\n",
       "      <td>2016-09-10 01:59:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HotTrends8</td>\n",
       "      <td>Google Hot Trends</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>774426965440856064</td>\n",
       "      <td>Ana Popovic Nothing Personal https://t.co/jMrq...</td>\n",
       "      <td>2016-09-10 01:59:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RadioMirabelle</td>\n",
       "      <td>Radio Mirabelle</td>\n",
       "      <td>Lorraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>774426649135869952</td>\n",
       "      <td>@TATERTRONIX Deluxe https://t.co/3fkWSJWzFp #j...</td>\n",
       "      <td>2016-09-10 01:57:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lorraine_jazz</td>\n",
       "      <td>Lorraine Jazz</td>\n",
       "      <td>Nancy, Lorraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>774426413294358528</td>\n",
       "      <td>Listening to Good People by Jack Johnson on ht...</td>\n",
       "      <td>2016-09-10 01:56:59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Latitude23R</td>\n",
       "      <td>Latitude23 Radio</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>774426407183101952</td>\n",
       "      <td>RT @TheMileHighShow: @roadonesouth  about to t...</td>\n",
       "      <td>2016-09-10 01:56:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Msantos_photo</td>\n",
       "      <td>Matt Santos</td>\n",
       "      <td>Arizona, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>774425523338420225</td>\n",
       "      <td>RT @RadioKvmr: Happy Birthday #OtisRedding (19...</td>\n",
       "      <td>2016-09-10 01:53:27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ms_laurencarter</td>\n",
       "      <td>Lauren Carter</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>774425446037336064</td>\n",
       "      <td>@Chiara Civello Here Is Everything https://t.c...</td>\n",
       "      <td>2016-09-10 01:53:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lorraine_jazz</td>\n",
       "      <td>Lorraine Jazz</td>\n",
       "      <td>Nancy, Lorraine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text          created_at  retweet_count  \\\n",
       "0   774432361832325120  RT @GDoblesMusic: ¬øUn poco de #blues para term... 2016-09-10 02:20:37              2   \n",
       "1   774432213802835968  #IWokeUp @McNeillShona https://t.co/Ofh71bdZOE... 2016-09-10 02:20:02              0   \n",
       "2   774431974354288640  #galveston #texas #blues #fuckinword @ Old Qua... 2016-09-10 02:19:05              0   \n",
       "3   774431387017474048  #BBKing #BluesLegend Live at the Regal by B.B.... 2016-09-10 02:16:45              0   \n",
       "4   774430888197259264  Listening to Looking Good by Magic Sam on http... 2016-09-10 02:14:46              0   \n",
       "5   774430346498768896  RT @HunterAHomistek: Stevie Ray Vaughan's best... 2016-09-10 02:12:37              1   \n",
       "6   774430248574324736  #doublebass #bass #bassguitar #jamsession #beb... 2016-09-10 02:12:14              0   \n",
       "7   774429935138209792  @Marlin Saner Rain For Africa https://t.co/3fk... 2016-09-10 02:10:59              0   \n",
       "8   774429930969042944  Now Playing, Little Freddie King ‚Äî Louisiana T... 2016-09-10 02:10:58              0   \n",
       "9   774429767223369728  Listen to my #awardwinningsong #moonblues on #... 2016-09-10 02:10:19              0   \n",
       "10  774428983261671424  #StLouis Rare NHL St. Louis #Blues Sean Glanvi... 2016-09-10 02:07:12              0   \n",
       "11  774428657477644288  @RVG Bad Habit https://t.co/3fkWSJWzFp #japan ... 2016-09-10 02:05:54              0   \n",
       "12  774427946585100289  RT @MECStateChamber: The MS #Blues Trail, now ... 2016-09-10 02:03:05              2   \n",
       "13  774427136694235136  #BBKing #BluesLegend B.B.KING - THERE MUST BE ... 2016-09-10 01:59:52              0   \n",
       "14  774426965440856064  Ana Popovic Nothing Personal https://t.co/jMrq... 2016-09-10 01:59:11              0   \n",
       "15  774426649135869952  @TATERTRONIX Deluxe https://t.co/3fkWSJWzFp #j... 2016-09-10 01:57:55              0   \n",
       "16  774426413294358528  Listening to Good People by Jack Johnson on ht... 2016-09-10 01:56:59              0   \n",
       "17  774426407183101952  RT @TheMileHighShow: @roadonesouth  about to t... 2016-09-10 01:56:58              1   \n",
       "18  774425523338420225  RT @RadioKvmr: Happy Birthday #OtisRedding (19... 2016-09-10 01:53:27              2   \n",
       "19  774425446037336064  @Chiara Civello Here Is Everything https://t.c... 2016-09-10 01:53:09              0   \n",
       "\n",
       "    favorite_count user_screen_name            user_name      user_location  \n",
       "0                0   matarosario831         Rosario Mata                     \n",
       "1                0    Lov3rzLov3You     Michelle #LOV3RZ          Worldwide  \n",
       "2                0        manny9000        manny salazar      Houston Texas  \n",
       "3                0       HotTrends8    Google Hot Trends                     \n",
       "4                0      Latitude23R     Latitude23 Radio        Phoenix, AZ  \n",
       "5                0         homistek             Mr marty       Planet earth  \n",
       "6                1    shulman_susan        susan shulman                     \n",
       "7                0    lorraine_jazz        Lorraine Jazz    Nancy, Lorraine  \n",
       "8                0        wnmcradio  WNMC Radio Playlist  Traverse City, MI  \n",
       "9                0      delaine2511      Vanessa Delaine          Australia  \n",
       "10               0    FaithCrossman       Faith Crossman                     \n",
       "11               0    lorraine_jazz        Lorraine Jazz    Nancy, Lorraine  \n",
       "12               0        JNewell53         Two Feathers                     \n",
       "13               0       HotTrends8    Google Hot Trends                     \n",
       "14               0   RadioMirabelle      Radio Mirabelle           Lorraine  \n",
       "15               0    lorraine_jazz        Lorraine Jazz    Nancy, Lorraine  \n",
       "16               0      Latitude23R     Latitude23 Radio        Phoenix, AZ  \n",
       "17               0    Msantos_photo          Matt Santos       Arizona, USA  \n",
       "18               0  ms_laurencarter        Lauren Carter     Houston, Texas  \n",
       "19               0    lorraine_jazz        Lorraine Jazz    Nancy, Lorraine  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This returns the first twenty items in your dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                1081\n",
      "Hatfield, Hertfordshire, UK      223\n",
      "London, England                  157\n",
      "Nancy, Lorraine                  130\n",
      "Phoenix, AZ                      123\n",
      "Lorraine                          92\n",
      "Worldwide                         51\n",
      "London                            37\n",
      "Casablanca, Grand Casablanca      25\n",
      "Traverse City, MI                 25\n",
      "Fort Lauderdale                   24\n",
      "Local, Everywhere!‚Ñ¢               23\n",
      "Los Angeles, CA                   20\n",
      "Birmingham                        20\n",
      "Mother Earth                      19\n",
      "Name: user_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#This gives you the top 15 places in user_location \n",
    "top_places = df[\"user_location\"].value_counts()[:15]\n",
    "print top_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#I used this function to help clean up and organize the unstructured data by removing common places to regular state abbreviations\n",
    "def cleanup(df):  \n",
    "    new_df = df.replace(to_replace = \"Hatfield, Hertfordshire, UK\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"United States\", value = \"US\")\n",
    "    new_df = new_df.replace(to_replace = \"London\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"London, GB\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"London, England\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"Traverse City, MI\", value = \"MI\")\n",
    "    new_df = new_df.replace(to_replace = \"Los Angeles, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"New York NY (Forest Hills) USA\", value = \"NY\")\n",
    "    new_df = new_df.replace(to_replace = \"Canada\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Los Angeles, California\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Birmingham\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"Lorraine\", value = \"France\")\n",
    "    new_df = new_df.replace(to_replace = \"Texas\", value = \"TX\")\n",
    "    new_df = new_df.replace(to_replace = \"Valencia\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"East Coast, N.J.\", value = \"NJ\")\n",
    "    new_df = new_df.replace(to_replace = \"Vancouver, British Columbia\", value = \"Canada\")\n",
    "    new_df = new_df.replace(to_replace = \"Longuyon, France\", value = \"France\")\n",
    "    new_df = new_df.replace(to_replace = \"Venezuela\", value = \"VE\")\n",
    "    new_df = new_df.replace(to_replace = \"Bluesville, Illinois\", value = \"IL\")\n",
    "    new_df = new_df.replace(to_replace = \"London, UK\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"New York\", value = \"NY\")\n",
    "    new_df = new_df.replace(to_replace = \"Chicago\", value = \"IL\")\n",
    "    new_df = new_df.replace(to_replace = \"London, Ontario\", value = \"Canada\")\n",
    "    new_df = new_df.replace(to_replace = \"Austin, TX\", value = \"TX\")\n",
    "    new_df = new_df.replace(to_replace = \"Sausalito, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Nashville, TN\", value = \"TN\")\n",
    "    new_df = new_df.replace(to_replace = \"Espa√±a\", value = \"Spain\")\n",
    "    new_df = new_df.replace(to_replace = \"Boston, MA\", value = \"MA\")\n",
    "    new_df = new_df.replace(to_replace = \"Sweden\", value = \"Sweden\")\n",
    "    new_df = new_df.replace(to_replace = \"Bogota, Colombia\", value = \"Colombia\")\n",
    "    new_df = new_df.replace(to_replace = \"Florida\", value = \"FL\")\n",
    "    new_df = new_df.replace(to_replace = \"California\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Illinois\", value = \"IL\")\n",
    "    new_df = new_df.replace(to_replace = \"Bergen County New Jersey\", value = \"NJ\")\n",
    "    new_df = new_df.replace(to_replace = \"Kula, Hawaii\", value = \"HI\")\n",
    "    new_df = new_df.replace(to_replace = \"Chicago, IL\", value = \"IL\")\n",
    "    new_df = new_df.replace(to_replace = \"Ottawa, Ontario\", value = \"Canada\")\n",
    "    new_df = new_df.replace(to_replace = \"Florence, SC\", value = \"SC\")\n",
    "    new_df = new_df.replace(to_replace = \"Hull Uk  (from MemphisTN-USA)\", value = \"TN\")\n",
    "    new_df = new_df.replace(to_replace = \"Seattle, WA\", value = \"WA\")\n",
    "    new_df = new_df.replace(to_replace = \"Michigan, USA\", value = \"MI\")\n",
    "    new_df = new_df.replace(to_replace = \"Fort Lauderdale\", value = \"FL\")\n",
    "    new_df = new_df.replace(to_replace = \"Los Angeles\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Lebanon Oregon USA\", value = \"OR\")\n",
    "    new_df = new_df.replace(to_replace = \"Flowery Branch, GA\", value = \"GA\")\n",
    "    new_df = new_df.replace(to_replace = \"New York, NY\", value = \"NY\")\n",
    "    new_df = new_df.replace(to_replace = \"St. Louis, MO\", value = \"MO\")\n",
    "    new_df = new_df.replace(to_replace = \"Utah\", value = \"UT\")\n",
    "    new_df = new_df.replace(to_replace = \"\", value = \"US\")\n",
    "    new_df = new_df.replace(to_replace = \"Paris, Ile-de-France\", value = \"France\")\n",
    "    new_df = new_df.replace(to_replace = \"United Kingdom\", value = \"UK\")\n",
    "    new_df = new_df.replace(to_replace = \"Toronto, Ontario\", value = \"Canada\")\n",
    "    new_df = new_df.replace(to_replace = \"Georgia\", value = \"GA\")\n",
    "    new_df = new_df.replace(to_replace = \"California, USA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Iowa, USA\", value = \"IA\")\n",
    "    new_df = new_df.replace(to_replace = \"Albany, OR\", value = \"OR\")\n",
    "    new_df = new_df.replace(to_replace = \"Miami Springs\", value = \"FL\")\n",
    "    new_df = new_df.replace(to_replace = \"Ohio\", value = \"OH\")\n",
    "    new_df = new_df.replace(to_replace = \"Arkansas\", value = \"AR\")\n",
    "    new_df = new_df.replace(to_replace = \"Atlanta, GA\", value = \"GA\")\n",
    "    new_df = new_df.replace(to_replace = \"Massachusetts\", value = \"MA\")\n",
    "    new_df = new_df.replace(to_replace = \"Indiana, USA\", value = \"IN\")\n",
    "    new_df = new_df.replace(to_replace = \"Miami Springs, Florida\", value = \"FL\")\n",
    "    new_df = new_df.replace(to_replace = \"NY, NY\", value = \"NY\")\n",
    "    new_df = new_df.replace(to_replace = \"Long Beach, Cal\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Mississippi\", value = \"MS\")\n",
    "    new_df = new_df.replace(to_replace = \"Wisconsin\", value = \"WI\")\n",
    "    new_df = new_df.replace(to_replace = \"Malibu, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Los Angeles / Hollywood\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Shelby, North Carolina\", value = \"NC\")\n",
    "    new_df = new_df.replace(to_replace = \"Beverly Hills, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Puyallup, WA\", value = \"WA\")\n",
    "    new_df = new_df.replace(to_replace = \"Tawas City, Michigan\", value = \"MI\")\n",
    "    new_df = new_df.replace(to_replace = \"Kentucky\", value = \"KT\")\n",
    "    new_df = new_df.replace(to_replace = \"Pennsylvania\", value = \"PN\")\n",
    "    new_df = new_df.replace(to_replace = \"Hollywood - Los Angeles, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"St Louis, Missouri, USA\", value = \"MS\")\n",
    "    new_df = new_df.replace(to_replace = \"New Jersey\", value = \"NJ\")\n",
    "    new_df = new_df.replace(to_replace = \"Connecticut, USA\", value = \"CT\")\n",
    "    new_df = new_df.replace(to_replace = \"Sacramento, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"San Rafael, CA\", value = \"CA\")\n",
    "    new_df = new_df.replace(to_replace = \"Houston, TX\", value = \"TX\")\n",
    "    new_df = new_df.replace(to_replace = \"texas\", value = \"TX\")\n",
    "    new_df = new_df.replace(to_replace = \"Phoenix, AZ\", value = \"AZ\")\n",
    "    return new_df \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#if you can't get the function to work just change it back to not being a function\n",
    "#clean_up(df)\n",
    "#print df['user_location'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrian\\Anaconda2\\lib\\site-packages\\pandas\\core\\common.py:488: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  mask = arr == x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US                              1090\n",
      "UK                               487\n",
      "Nancy, Lorraine                  130\n",
      "AZ                               124\n",
      "France                           107\n",
      "CA                                53\n",
      "Worldwide                         51\n",
      "IL                                44\n",
      "MI                                29\n",
      "FL                                28\n",
      "NJ                                27\n",
      "Casablanca, Grand Casablanca      25\n",
      "Local, Everywhere!‚Ñ¢               23\n",
      "Mother Earth                      19\n",
      "Sweden                            17\n",
      "Name: user_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Prints out the top 15 places in user_location after clean up has been used on the dataframe\n",
    "clean = cleanup(df)\n",
    "print clean['user_location'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This line was used just in case there were any values in user_location that weren't read in as strings\n",
    "#new_df.user_location = new_df.user_location.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This line below takes the clean dataframe and puts it into a .csv file with a utf-8 encoding\n",
    "#clean.to_csv('summer8.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This part reads in .csv files from different days\n",
    "summer = pd.read_csv(os.path.join('summer7.csv'))\n",
    "summer2 = pd.read_csv(os.path.join('summer8.csv'))\n",
    "summer3 = pd.read_csv(os.path.join('summer.csv'))\n",
    "\n",
    "#These lines join the three separate dataframes above and joins them all together into one \n",
    "result = summer.append(summer2)\n",
    "result = result.append(summer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US                              1219\n",
      "UK                               521\n",
      "AZ                               149\n",
      "France                           116\n",
      "CA                               102\n",
      "MI                                58\n",
      "IL                                56\n",
      "Worldwide                         52\n",
      "TN                                45\n",
      "Herne Bay Kent CT6                32\n",
      "Casablanca, Grand Casablanca      28\n",
      "NY                                21\n",
      "espelkamp germany                 19\n",
      "TX                                19\n",
      "Sweden                            15\n",
      "Name: user_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#This cleans up the one big dataframe that we now have and outputs the top 15 places \n",
    "df = cleanup(result)\n",
    "print df['user_location'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This takes all the values in the dataframe that has its user_location in the same state and separates them into their own \n",
    "#dataframes\n",
    "CA = df[df['user_location'] == 'CA']\n",
    "TX = df[df['user_location'] == 'TX']\n",
    "AZ = df[df['user_location'] == 'AZ']\n",
    "MI = df[df['user_location'] == 'MI']\n",
    "TN = df[df['user_location'] == 'TN']\n",
    "IL = df[df['user_location'] == 'IL']\n",
    "USA = df[df['user_location'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This takes the combined dataframe we had from earlier and puts it into its own .csv file \n",
    "df.to_csv('combined.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA: https://t.co/vYclMJhDZu\r\n",
      "\r\n",
      "Some lunchtime #Blues for you\r\n",
      "@TheRealBuddyGuy and SRV\r\n",
      "Passing fwd = enjoymentüíô‚ùóÔ∏è https://t.co/nC6elJRpl6\n",
      "Retweet count: 29.0\n",
      "\n",
      "TX: So pumped to be a part of @kpboomboom #album #release #music #indie #blues #artist #concert‚Ä¶ https://t.co/BrpiKeQqh5\n",
      "Retweet count: 296.0\n",
      "\n",
      "AZ: RT @Fender: RT @rtruesdale50: These Fender Blues Deville harps are very cool. Excellent tone and vibe. @Fender #harmonica #blues https://t.‚Ä¶\n",
      "Retweet count: 41.0\n",
      "\n",
      "IL: the #blues defined, by @bluesAllstars How #chicago does #music https://t.co/p1Q4S2tfqx\n",
      "Retweet count: 15.0\n",
      "\n",
      "MI: Slow Train - Joe Bonamassa | Blues |425300105 #Blues https://t.co/B9wqYx3OJR #Blues\n",
      "Retweet count: 3.0\n",
      "\n",
      "TN: https://t.co/L0CegLDUps  #music ‚Ä¶https://t.co/g192SopB6J   https://t.co/8mgUvTYl32 ‚Ä¶  https://t.co/qpCI2ngfuY  #pop #blues\n",
      "Retweet count: 11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This function prints the text of the tweet with the max number of retweets as well as max retweet number \n",
    "def max_print_state(df): \n",
    "    state = str(df['user_location'].iloc[0])\n",
    "    print state + \": \" + df['text'].max()\n",
    "    print \"Retweet count: \" + str(df['retweet_count'].max())\n",
    "    print\n",
    "\n",
    "max_print_state(CA)\n",
    "max_print_state(TX)\n",
    "max_print_state(AZ)\n",
    "max_print_state(IL)\n",
    "max_print_state(MI)\n",
    "max_print_state(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I used this function to print out the text of a tweet with the retweet_count amount above the percentile defined\n",
    "def top_tweets(df):\n",
    "    state = str(df['user_location'].iloc[0])\n",
    "    print state + \": \" + df['text'].max() + '\\n' \n",
    "    print df.sort('retweet_count', ascending = True)[:5].text\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA: https://t.co/vYclMJhDZu\r\n",
      "\r\n",
      "Some lunchtime #Blues for you\r\n",
      "@TheRealBuddyGuy and SRV\r\n",
      "Passing fwd = enjoymentüíô‚ùóÔ∏è https://t.co/nC6elJRpl6\n",
      "\n",
      "1        Listening to #JimmyRushing singing the #blues! #NowPlaying \"T'aint Nobody's Bizness\" https://t.co/uNM7XjL9ab\n",
      "2428    #morning #blues #bus #ride #september62014 #classic #blackandwhite #glasses #immortal @ Los‚Ä¶ https://t.co/...\n",
      "2315    Especial Entrevista a Jose Luis Acosta Can Blues Pink Tone Jueves 9 PM #BLUES # BluesRock en Las Fronteras...\n",
      "2089    @AmeriBluesScene @Bluescentric  Nice to see a #Canadian #blues #musician in that list @sweetharrisonk ,unl...\n",
      "2060    \"Slippin and Slidin\" at The Malibu Chili Cook-Off Sat #Rock #Blues #guitarsolo #slideguitar‚Ä¶ https://t.co/...\n",
      "Name: text, dtype: object\n",
      "\n",
      "TX: So pumped to be a part of @kpboomboom #album #release #music #indie #blues #artist #concert‚Ä¶ https://t.co/BrpiKeQqh5\n",
      "\n",
      "1276          Currently on air: TOTAL GRAVEYARD BLUES on https://t.co/11jvnMonEq  #blues #delta #harambe #BLM #Austin\n",
      "252                                           Charles Brown - Drifting #Blues - 1945 - https://t.co/Ggzctd8BU8 #Texas\n",
      "60                     I took this picture of Hope's boy #OmarDykes ! #Blues #Guitar #Awesome https://t.co/AA5uTPPvhl\n",
      "625     #musicismyhappiness #music #musicart #artistic #creative #jazz #blues #musician #rock #hip-hop #r&amp;b #p...\n",
      "735             A Guide to Finding #Blues and #Jazz #Music in #Austin https://t.co/3SVRMLWZDn https://t.co/Hfv2jFHQbj\n",
      "Name: text, dtype: object\n",
      "\n",
      "AZ: RT @Fender: RT @rtruesdale50: These Fender Blues Deville harps are very cool. Excellent tone and vibe. @Fender #harmonica #blues https://t.‚Ä¶\n",
      "\n",
      "11      Listening to Basin Street Blues by Louis Armstrong on https://t.co/99ZGXxa5mB! #Blues #np #nowplaying\n",
      "2072     Listening to I Want A Little Girl by Eric Clapton on https://t.co/99ZGXxa5mB! #Blues #np #nowplaying\n",
      "2015     Listening to Jailhouse Rock by The Blues Brothers on https://t.co/99ZGXxa5mB! #Blues #np #nowplaying\n",
      "1984                  Listening to Monsoon by Jack Johnson on https://t.co/99ZGXxa5mB! #Blues #np #nowplaying\n",
      "1960    Listening to Walkin' Thru the Park by Muddy Waters on https://t.co/99ZGXxa5mB! #Blues #np #nowplaying\n",
      "Name: text, dtype: object\n",
      "\n",
      "IL: the #blues defined, by @bluesAllstars How #chicago does #music https://t.co/p1Q4S2tfqx\n",
      "\n",
      "159                                              Playing at August 25, 2016 at 09:30PM: Chicago R&amp;B Kings  #blues\n",
      "2297                    Tonight: JW-Jones! Watch live on https://t.co/4PUV25aWbL #Live #Blues https://t.co/DBQRw0hwom\n",
      "792                     Tonight: JW-Jones! Watch live on https://t.co/4PUV25aWbL #Live #Blues https://t.co/DBQRw0hwom\n",
      "1936                           Playing at September 06, 2016 at 06:00PM: Matt Hendricks (Acoustic Dinner Set)  #blues\n",
      "42      hot new #chicago #blues from Maurice John Vaughn...just in time for #NFL #football #ItsAManThing. https://...\n",
      "Name: text, dtype: object\n",
      "\n",
      "TN: https://t.co/L0CegLDUps  #music ‚Ä¶https://t.co/g192SopB6J   https://t.co/8mgUvTYl32 ‚Ä¶  https://t.co/qpCI2ngfuY  #pop #blues\n",
      "\n",
      "93      Cason Simmons and Wilson Harwood leading out on some #folsomprison #blues in #probluesjam Round‚Ä¶ https://t...\n",
      "2168    Subscribe to #Jazz #Country #Blues #Musician @Bronzie9 https://t.co/yvmqTYbNll on #YouTube https://t.co/bk...\n",
      "2169    Subscribe to #Jazz #Country #Blues #Musician @Bronzie9 https://t.co/893xGyPKTV on #YouTube https://t.co/Il...\n",
      "2172    Subscribe to #Jazz #Country #Blues #Musician @Bronzie9 https://t.co/eXnyneI9il on #YouTube https://t.co/Nl...\n",
      "2173    Subscribe to #Jazz #Country #Blues #Musician @Bronzie9 https://t.co/RMUKXMe6Ls on #YouTube https://t.co/Ht...\n",
      "Name: text, dtype: object\n",
      "\n",
      "MI: Slow Train - Joe Bonamassa | Blues |425300105 #Blues https://t.co/B9wqYx3OJR #Blues\n",
      "\n",
      "135                         Blue and Lonesome - Little Walter | Blues |15038943 #Blues https://t.co/oXqm8nLHbO #Blues\n",
      "526     Now Playing, Eric Bibb and North Country Far with Danny Thompson ‚Äî King Size Bed from B-008 _ The Happiest...\n",
      "1964             Now Playing, Keb' Mo' ‚Äî More Than One Way Home from DB-008 _ That Hot Pink Blues Album #music #Blues\n",
      "1971                Now Playing, Norman Taylor ‚Äî Special Rider Blues from B-014 _ Delaware to the Delta #music #Blues\n",
      "1976                       Now Playing, Tota Blues ‚Äî Last Fair Deal from B-007 _ Veinte A√±os No Es Nada #music #Blues\n",
      "Name: text, dtype: object\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrian\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "top_tweets(CA)\n",
    "top_tweets(TX)\n",
    "top_tweets(AZ)\n",
    "top_tweets(IL)\n",
    "top_tweets(TN)\n",
    "top_tweets(MI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
